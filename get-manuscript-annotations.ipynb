{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get annotations for annotated manuscripts\n",
    "\n",
    "Currently uses the CGType:General annotations as an indication that we should pull down the annotations. There is no PMID tag, so we have to pull the PMID from the text of the CGType:General tag.\n",
    "\n",
    "**Note**: In order to use this, you have to have a hypothes.is API token with permissions to access the relevant hypothes.is group. It should be included in a file called \"token\" as a single line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import yaml\n",
    "import os\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = open('token').read().rstrip()\n",
    "api_endpoint = 'https://hypothes.is/api'\n",
    "group = 'DRL6xW1v'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_annotations(querydata, token=token):\n",
    "    '''Fetches, using the already-defined token and handling pagination'''\n",
    "    # FIXME: search_after is described as more efficient in the API docs, but I don't know if it handles timestamp collisions\n",
    "    fetched = []\n",
    "    while True:\n",
    "        response = requests.post(api_endpoint + '/search',\n",
    "                            data=querydata,\n",
    "                            headers={'Authorization': 'Bearer %s'%token}).json()\n",
    "        fetched += response['rows']\n",
    "        if response['total'] == len(fetched):\n",
    "            # FIXME: kludge! only here until these broken annotations are removed\n",
    "            return [x for x in fetched if not 'libproxy.lib.unc.edu' in x['uri']]\n",
    "        querydata['offset'] = len(fetched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_tagged_manuscript = search_for_annotations({\n",
    "        'group': group,\n",
    "        'sort': 'created',\n",
    "        'order': 'desc',\n",
    "        'limit': 200,\n",
    "        'tag': 'CGType:Manuscript'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It appears as though hyp.is stores urls with query parameters-- which might be necessary in some\n",
    "# cases, but I'm also not sure this is completely safe, so I don't want to keep them. So that\n",
    "# is what this mess is about.\n",
    "\n",
    "# later on, we'll call this for all of the downloaded data\n",
    "\n",
    "def json_recursive(data, pre=None, post=None):\n",
    "    '''Recursively works through data, applying the functions pre/post(value, key) as it goes'''\n",
    "    if isinstance(data, dict):\n",
    "        output = {}\n",
    "        for (k,v) in data.items():\n",
    "            if pre is not None:\n",
    "                v, k = pre(v, k)\n",
    "            v = json_recursive(v, pre, post)\n",
    "            if post is not None:\n",
    "                v, k = post(v, k)\n",
    "            output[k] = v\n",
    "        return output\n",
    "    if isinstance(data, list):\n",
    "        output = []\n",
    "        for i,v in enumerate(data):\n",
    "            if pre is not None:\n",
    "                v, k = pre(v, i)\n",
    "            v = json_recursive(v, pre, post)\n",
    "            if post is not None:\n",
    "                v, k = post(v, i)\n",
    "            output.append(v)\n",
    "        return output\n",
    "    return data\n",
    "\n",
    "def urls_without_queryparams(v,k):\n",
    "    if k in ('uri', 'source', 'incontext'):\n",
    "        v = v.split('?',1)[0]\n",
    "    return v,k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pmid(cg_manuscript_annotation):\n",
    "    for t in cg_manuscript_annotation['tags']:\n",
    "        m = re.search(r'PMID:\\s*(\\d+)', t)\n",
    "        if m:\n",
    "            return m.group(1)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('downloaded_data', exist_ok=True)\n",
    "for manuscript_tag_annotation in annotations_tagged_manuscript:\n",
    "    pmid = find_pmid(manuscript_tag_annotation)\n",
    "    if pmid is not None:\n",
    "        manuscript_annotations_json = search_for_annotations(\n",
    "            querydata={\n",
    "                'group': group,\n",
    "                'sort': 'created',\n",
    "                'order': 'asc',\n",
    "                'limit': 200,\n",
    "                'uri': manuscript_tag_annotation['uri']\n",
    "            })\n",
    "        with open(os.path.join('downloaded_data', 'PMID%s.json'%pmid), 'wt') as jsonf:\n",
    "            json.dump(manuscript_annotations_json, jsonf, indent=2)\n",
    "        with open(os.path.join('downloaded_data', 'PMID%s.yaml'%pmid), 'wt') as yamlf:\n",
    "            yaml.dump(manuscript_annotations_json, yamlf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
